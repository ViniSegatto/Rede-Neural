#modelo de rede neural convolucional com o dataset MNIST

from tensorflow.keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

index = np.random.choice(np.arange(len(X_train)), 24, replace = False)

figure, axes = plt.subplots(nrows = 4, ncols = 6, figsize = (16, 9))

for item in zip(axes.ravel(), X_train[index], y_train[index]):
    axes, image, target = item
    axes.imshow(image, cmap = plt.cm.gray_r)
    axes.set_xticks([])
    axes.set_yticks([])
    axes.set_title(target)
plt.tight_layout

''' Visualização de imagens para treino '''
''' Definindo treino '''

X_train = X_train.reshape((60000, 28, 28, 1))
X_train.shape

''' Definindo teste ''' 

X_test = X_test.reshape((10000, 28, 28, 1))
X_test.shape

X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

from tensorflow.keras.utils import to_categorical

y_train = to_categorical(y_train)
y_train.shape

y_test = to_categorical(y_test)
y_test

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from keras.layers import Flatten, Dense

cnn = Sequential()

cnn.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (28, 28, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))
cnn.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'))
cnn.add(MaxPooling2D(pool_size = (2, 2)))
cnn.add(Flatten())
cnn.add(Dense(units = 128, activation = 'relu'))
cnn.add(Dense(units = 10, activation = 'softmax'))

cnn.summary()

cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

history = cnn.fit(X_train, y_train, epochs = 5, batch_size = 32, validation_split = 0.1)

loss, accuracy = cnn.evaluate(X_test, y_test)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label = 'Training accuracy')
plt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()

plt.plot(epochs, loss, 'bo', label = 'Training loss')
plt.plot(epochs, val_loss, 'b', label = 'Validation loss')
plt.title('Training and validation loss')
plt.legend()

predictions = cnn.predict(X_test)

for index, probability in enumerate(y_test[0]):
    print(f'{index}: {probability:.10%}')
    
for index, probability in enumerate(predictions[0]):
    print(f'{index}: {probability:.10%}')

images = X_test.reshape((10000, 28, 28))

incorrect_predictions = []

for i, (p, e) in enumerate(zip(predictions, y_test)):
    predicted, expected = np.argmax(p), np.argmax(e)
    
    if predicted != expected:
        incorrect_predictions.append((i, images[i], predicted, expected))
        
len(incorrect_predictions)

figure, axes = plt.subplots(nrows = 4, ncols = 6, figsize = (16, 12))

for axes, item in zip(axes.ravel(), incorrect_predictions):
    index, image, predicted, expected = item
    axes.imshow(image, cmap = plt.cm.gray_r)
    axes.set_xticks([])
    axes.set_yticks([])
    axes.set_title(f'index: {index}\np: {predicted}; e: {expected}')
plt.tight_layout()

index, image, predicted, expected = incorrect_predictions[0]

for index, probability in enumerate(predictions[index]):
    print(f'{index}: {probability:.10%}')
